{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "coords = re.findall(\"\\(.+\\)\", \"1110 Boston Road\\nBronx, NY 10456\\n(40.8276026690005, -73.90447525699966)\")\n",
    "type(coords[0])\n",
    "\n",
    "## Funcion para extraer una cadena entre parentesis.\n",
    "\n",
    "#import re\n",
    "#def find_lat(loc):\n",
    "#    coords = re.findall(\"\\(.+\\)\", \"1110 Boston Road\\nBronx, NY 10456\\n(40.8276026690005, -73.90447525699966)\")\n",
    "#    lat = coords[0].split(\",\")[0].replace(\"(\", \"\")\n",
    "#    return lat\n",
    "    \n",
    "#data[\"hs_directory\"][\"lat\"]=data[\"hs_directory\"][\"Location 1\"].apply(find_lat)\n",
    "\n",
    "#print(data[\"hs_directory\"][\"lat\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -73.90447525699966)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = re.findall(\"\\(.+\\)\", \"1110 Boston Road\\nBronx, NY 10456\\n(40.8276026690005, -73.90447525699966)\")\n",
    "long = coords[0].split(\",\")[1].replace(\"(\", \"\")\n",
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -73.90447525699966'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long.replace(\")\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of strings, convirting columns to numeric data, creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-23-d8fb629bd037>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-d8fb629bd037>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    coords = re.findall(\"\\(.+\\)\",loc\") ## Selecting just inside parenthesis\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "def find_long(loc):\n",
    "    coords = re.findall(\"\\(.+\\)\",loc\") ## Selecting just inside parenthesis\n",
    "    long = coords[0].split(\",\")[1].replace(\")\", \"\").strip()\n",
    "    return long\n",
    "\n",
    "data[\"hs_directory\"][\"lon\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_long)\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = pd.to_numeric(data[\"hs_directory\"][\"lat\"], errors=\"coerce\")\n",
    "\n",
    "data[\"hs_directory\"][\"lon\"] = pd.to_numeric(data[\"hs_directory\"][\"lon\"],errors=\"coerce\")\n",
    "\n",
    "print(data[\"hs_directory\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "\n",
    "data = {}\n",
    "for files in data_files:\n",
    "    df = pd.read_csv(\"schools/{0}\".format(files))\n",
    "    dfname = files.replace(\".csv\",\"\")\n",
    "    data[dfname] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey=pd.read_csv(\"schools/survey_all.txt\",delimiter=\"\\t\",encoding=\"windows-1252\")\n",
    "\n",
    "d75_survey=pd.read_csv(\"schools/survey_d75.txt\",delimiter=\"\\t\",encoding=\"windows-1252\")\n",
    "\n",
    "survey=pd.concat([all_survey, d75_survey], axis=0)\n",
    "print(survey.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN  rr_s  rr_t  rr_p    N_s   N_t    N_p  saf_p_11  com_p_11  eng_p_11  \\\n",
      "0  01M015   NaN    88    60    NaN  22.0   90.0       8.5       7.6       7.5   \n",
      "1  01M019   NaN   100    60    NaN  34.0  161.0       8.4       7.6       7.6   \n",
      "2  01M020   NaN    88    73    NaN  42.0  367.0       8.9       8.3       8.3   \n",
      "3  01M034  89.0    73    50  145.0  29.0  151.0       8.8       8.2       8.0   \n",
      "4  01M063   NaN   100    60    NaN  23.0   90.0       8.7       7.9       8.1   \n",
      "\n",
      "      ...      eng_t_11  aca_t_11  saf_s_11  com_s_11  eng_s_11  aca_s_11  \\\n",
      "0     ...           7.6       7.9       NaN       NaN       NaN       NaN   \n",
      "1     ...           8.9       9.1       NaN       NaN       NaN       NaN   \n",
      "2     ...           6.8       7.5       NaN       NaN       NaN       NaN   \n",
      "3     ...           6.8       7.8       6.2       5.9       6.5       7.4   \n",
      "4     ...           7.8       8.1       NaN       NaN       NaN       NaN   \n",
      "\n",
      "   saf_tot_11  com_tot_11  eng_tot_11  aca_tot_11  \n",
      "0         8.0         7.7         7.5         7.9  \n",
      "1         8.5         8.1         8.2         8.4  \n",
      "2         8.2         7.3         7.5         8.0  \n",
      "3         7.3         6.7         7.1         7.9  \n",
      "4         8.5         7.6         7.9         8.0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "survey[\"DBN\"] = survey[\"dbn\"]\n",
    "\n",
    "survey_fields = [\n",
    "    \"DBN\", \n",
    "    \"rr_s\", \n",
    "    \"rr_t\", \n",
    "    \"rr_p\", \n",
    "    \"N_s\", \n",
    "    \"N_t\", \n",
    "    \"N_p\", \n",
    "    \"saf_p_11\", \n",
    "    \"com_p_11\", \n",
    "    \"eng_p_11\", \n",
    "    \"aca_p_11\", \n",
    "    \"saf_t_11\", \n",
    "    \"com_t_11\", \n",
    "    \"eng_t_11\", \n",
    "    \"aca_t_11\", \n",
    "    \"saf_s_11\", \n",
    "    \"com_s_11\", \n",
    "    \"eng_s_11\", \n",
    "    \"aca_s_11\", \n",
    "    \"saf_tot_11\", \n",
    "    \"com_tot_11\", \n",
    "    \"eng_tot_11\", \n",
    "    \"aca_tot_11\",\n",
    "]\n",
    "survey = survey.loc[:,survey_fields]\n",
    "data[\"survey\"] = survey\n",
    "\n",
    "print(survey.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hs_directory\"][\"DBN\"] = data[\"hs_directory\"][\"dbn\"]\n",
    "\n",
    "def pad_csd(num):\n",
    "    string_representation = str(num)\n",
    "    if len(string_representation) > 1:\n",
    "        return string_representation\n",
    "    else:\n",
    "        return string_representation.zfill(2)\n",
    "    \n",
    "data[\"class_size\"][\"padded_csd\"] = data[\"class_size\"][\"CSD\"].apply(pad_csd)\n",
    "data[\"class_size\"][\"DBN\"] = data[\"class_size\"][\"padded_csd\"] + data[\"class_size\"][\"SCHOOL CODE\"]\n",
    "print(data[\"class_size\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size=data[\"class_size\"]\n",
    "class_size=class_size[class_size[\"GRADE \"] == \"09-12\"]\n",
    "class_size=class_size[class_size[\"PROGRAM TYPE\"] == \"GEN ED\"]\n",
    "print(class_size.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Average Class Sizes\n",
    "\n",
    "- Find the average values for each column associated with each DBN in class_size.\n",
    "    - Use the pandas.DataFrame.groupby() method to group class_size by DBN.\n",
    "    - Use the agg() method on the resulting pandas.core.groupby object, along with the numpy.mean() function as an argument, to calculate the average of each group.\n",
    "    -Assign the result back to class_size.\n",
    "- Reset the index to make DBN a column again.\n",
    "     - Use the pandas.DataFrame.reset_index() method, along with the keyword argument inplace=True.\n",
    "- Assign class_size back to the class_size key of the data dictionary.\n",
    "- Display the first few rows of data[\"class_size\"] to verify that everything went okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "newclass_size=class_size.groupby(\"DBN\").agg(numpy.mean).reset_index()\n",
    "newclass_size.reset_index(inplace=True)\n",
    "data[\"class_size\"] = newclass_size\n",
    "print(data[\"class_size\"].head()) # Se realiza la media de cada una de las columnas agrupadas por grupo DBN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensing the Demographics Data Set\n",
    "\n",
    "- Filter demographics, only selecting rows in data[\"demographics\"] where schoolyear is 20112012.\n",
    "    - schoolyear is actually an integer, so be careful about how you perform your comparison.\n",
    "- Display the first few rows of data[\"demographics\"] to verify that the filtering worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=data[\"demographics\"]\n",
    "demo=demo[demo[\"schoolyear\"] == 20112012 ]\n",
    "data[\"demographics\"] = demo\n",
    "data[\"demographics\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensing the Graduation Data Set\n",
    "\n",
    "- Filter graduation, only selecting rows where the Cohort column equals 2006.\n",
    "- Filter graduation, only selecting rows where the Demographic column equals Total Cohort.\n",
    "- Display the first few rows of data[\"graduation\"] to verify that everything worked properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo1=data[\"graduation\"]\n",
    "demo1=demo1[(demo1[\"Cohort\"] == \"2006\") & (demo1[\"Demographic\"] == \"Total Cohort\")]\n",
    "data[\"graduation\"] = demo1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting AP Test Scores \n",
    "- Convert each of the following columns in ap_2010 to numeric values using the pandas.to_numeric() function with the keyword argument errors=\"coerce\".\n",
    "    - AP Test Takers\n",
    "    - Total Exams Taken\n",
    "    - Number of Exams with scores 3 4 or 5\n",
    "- Display the column types using the dtypes attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']\n",
    "\n",
    "for i in cols:\n",
    "    s = data[\"ap_2010\"][i]\n",
    "    data[\"ap_2010\"][i]=pd.to_numeric(s, errors=\"coerce\")\n",
    "data.dtypes\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Inner Joins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                        SCHOOL NAME  \\\n",
      "0  01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                         EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M509                            MARTA VALLE HIGH SCHOOL   \n",
      "4  01M539  NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                     44                             390                 433   \n",
      "4                    159                             522                 574   \n",
      "\n",
      "  SAT Writing Avg. Score                      SchoolName  AP Test Takers   \\\n",
      "0                    363                             NaN              NaN   \n",
      "1                    366    UNIVERSITY NEIGHBORHOOD H.S.             39.0   \n",
      "2                    370          EAST SIDE COMMUNITY HS             19.0   \n",
      "3                    384                             NaN              NaN   \n",
      "4                    525  NEW EXPLORATIONS SCI,TECH,MATH            255.0   \n",
      "\n",
      "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \\\n",
      "0                NaN                                   NaN   \n",
      "1               49.0                                  10.0   \n",
      "2               21.0                                   NaN   \n",
      "3                NaN                                   NaN   \n",
      "4              377.0                                 191.0   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "1                        ...                           \n",
      "2                        ...                           \n",
      "3                        ...                           \n",
      "4                        ...                           \n",
      "\n",
      "                                          priority02  \\\n",
      "0  Then to Manhattan students or residents who at...   \n",
      "1  For M35B only: Open only to students whose hom...   \n",
      "2                    Then to New York City residents   \n",
      "3            Then to Manhattan students or residents   \n",
      "4                    Then to New York City residents   \n",
      "\n",
      "                                          priority03  \\\n",
      "0  Then to New York City residents who attend an ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                    Then to New York City residents   \n",
      "4                                                NaN   \n",
      "\n",
      "                                priority04                       priority05  \\\n",
      "0  Then to Manhattan students or residents  Then to New York City residents   \n",
      "1                                      NaN                              NaN   \n",
      "2                                      NaN                              NaN   \n",
      "3                                      NaN                              NaN   \n",
      "4                                      NaN                              NaN   \n",
      "\n",
      "  priority06 priority07 priority08 priority09 priority10  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN   \n",
      "2        NaN        NaN        NaN        NaN        NaN   \n",
      "3        NaN        NaN        NaN        NaN        NaN   \n",
      "4        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "                                          Location 1  \n",
      "0  220 Henry Street\\nNew York, NY 10002\\n(40.7137...  \n",
      "1  200 Monroe Street\\nNew York, NY 10002\\n(40.712...  \n",
      "2  420 East 12 Street\\nNew York, NY 10009\\n(40.72...  \n",
      "3  145 Stanton Street\\nNew York, NY 10002\\n(40.72...  \n",
      "4  111 Columbia Street\\nNew York, NY 10002\\n(40.7...  \n",
      "\n",
      "[5 rows x 247 columns]\n",
      "(363, 247)\n"
     ]
    }
   ],
   "source": [
    "to_merge = [\"class_size\", \"demographics\", \"survey\", \"hs_directory\"]\n",
    "\n",
    "for m in to_merge:\n",
    "    combined = combined.merge(data[m], on=\"DBN\", how=\"inner\")\n",
    "\n",
    "print(combined.head(5))\n",
    "print(combined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Left Joins\n",
    "\n",
    "- Use the pandas pandas.DataFrame.merge() method to merge the ap_2010 data set into combined.\n",
    "    - Make sure to specify how=\"left\" as a keyword argument to indicate the correct join type.\n",
    "    - Make sure to assign the result of the merge operation back to combined.\n",
    "- Use the pandas df.merge() method to merge the graduation data set into combined.\n",
    "    - Make sure to specify how=\"left\" as a keyword argument to get the correct join type.\n",
    "    - Make sure to assign the result of the merge operation back to combined.\n",
    "- Display the first few rows of combined to verify that the correct operations occurred.\n",
    "- Use the pandas.DataFrame.shape attribute to display the shape of the dataframe and see how many rows now exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                    SCHOOL NAME  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                      7                             414                 401   \n",
      "4                     44                             390                 433   \n",
      "\n",
      "  SAT Writing Avg. Score                    SchoolName  AP Test Takers   \\\n",
      "0                    363                           NaN              NaN   \n",
      "1                    366  UNIVERSITY NEIGHBORHOOD H.S.             39.0   \n",
      "2                    370        EAST SIDE COMMUNITY HS             19.0   \n",
      "3                    359                           NaN              NaN   \n",
      "4                    384                           NaN              NaN   \n",
      "\n",
      "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \\\n",
      "0                NaN                                   NaN   \n",
      "1               49.0                                  10.0   \n",
      "2               21.0                                   NaN   \n",
      "3                NaN                                   NaN   \n",
      "4                NaN                                   NaN   \n",
      "\n",
      "             ...            Regents w/o Advanced - n  \\\n",
      "0            ...                                  36   \n",
      "1            ...                                  34   \n",
      "2            ...                                  67   \n",
      "3            ...                                 NaN   \n",
      "4            ...                                  23   \n",
      "\n",
      "  Regents w/o Advanced - % of cohort Regents w/o Advanced - % of grads  \\\n",
      "0                              46.2%                             83.7%   \n",
      "1                              27.4%                             64.2%   \n",
      "2                74.400000000000006%                             95.7%   \n",
      "3                                NaN                               NaN   \n",
      "4                              27.4%                             48.9%   \n",
      "\n",
      "   Local - n Local - % of cohort Local - % of grads Still Enrolled - n  \\\n",
      "0          7                  9%              16.3%                 16   \n",
      "1         11                8.9%              20.8%                 46   \n",
      "2          3                3.3%               4.3%                 15   \n",
      "3        NaN                 NaN                NaN                NaN   \n",
      "4          7  8.300000000000001%              14.9%                 25   \n",
      "\n",
      "  Still Enrolled - % of cohort Dropped Out - n Dropped Out - % of cohort  \n",
      "0                        20.5%              11                     14.1%  \n",
      "1                        37.1%              20       16.100000000000001%  \n",
      "2                        16.7%               5                      5.6%  \n",
      "3                          NaN             NaN                       NaN  \n",
      "4                        29.8%               5                        6%  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "(479, 32)\n"
     ]
    }
   ],
   "source": [
    "combined = data[\"sat_results\"]\n",
    "combined = combined.merge(data[\"ap_2010\"], on=\"DBN\", how=\"left\")\n",
    "combined = combined.merge(data[\"graduation\"], on=\"DBN\", how=\"left\")\n",
    "print(combined.head(5))\n",
    "print(combined.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Inner Joins\n",
    "\n",
    "- Merge class_size into combined. Then, merge demographics, survey, and hs_directory into combined one by one, in that order.\n",
    "    - Be sure to follow the exact order above.\n",
    "    - Remember to specify the correct column to join on, as well as the correct join type.\n",
    "- Display the first few rows of combined to verify that the correct operations occurred.\n",
    "- Call pandas.DataFrame.shape() to display the shape of the dataframe to see how many rows now exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                        SCHOOL NAME  \\\n",
      "0  01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                         EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M509                            MARTA VALLE HIGH SCHOOL   \n",
      "4  01M539  NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                     44                             390                 433   \n",
      "4                    159                             522                 574   \n",
      "\n",
      "  SAT Writing Avg. Score                      SchoolName  AP Test Takers   \\\n",
      "0                    363                             NaN              NaN   \n",
      "1                    366    UNIVERSITY NEIGHBORHOOD H.S.             39.0   \n",
      "2                    370          EAST SIDE COMMUNITY HS             19.0   \n",
      "3                    384                             NaN              NaN   \n",
      "4                    525  NEW EXPLORATIONS SCI,TECH,MATH            255.0   \n",
      "\n",
      "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \\\n",
      "0                NaN                                   NaN   \n",
      "1               49.0                                  10.0   \n",
      "2               21.0                                   NaN   \n",
      "3                NaN                                   NaN   \n",
      "4              377.0                                 191.0   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "1                        ...                           \n",
      "2                        ...                           \n",
      "3                        ...                           \n",
      "4                        ...                           \n",
      "\n",
      "                                          priority02  \\\n",
      "0  Then to Manhattan students or residents who at...   \n",
      "1  For M35B only: Open only to students whose hom...   \n",
      "2                    Then to New York City residents   \n",
      "3            Then to Manhattan students or residents   \n",
      "4                    Then to New York City residents   \n",
      "\n",
      "                                          priority03  \\\n",
      "0  Then to New York City residents who attend an ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                    Then to New York City residents   \n",
      "4                                                NaN   \n",
      "\n",
      "                                priority04                       priority05  \\\n",
      "0  Then to Manhattan students or residents  Then to New York City residents   \n",
      "1                                      NaN                              NaN   \n",
      "2                                      NaN                              NaN   \n",
      "3                                      NaN                              NaN   \n",
      "4                                      NaN                              NaN   \n",
      "\n",
      "  priority06 priority07 priority08 priority09 priority10  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN   \n",
      "2        NaN        NaN        NaN        NaN        NaN   \n",
      "3        NaN        NaN        NaN        NaN        NaN   \n",
      "4        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "                                          Location 1  \n",
      "0  220 Henry Street\\nNew York, NY 10002\\n(40.7137...  \n",
      "1  200 Monroe Street\\nNew York, NY 10002\\n(40.712...  \n",
      "2  420 East 12 Street\\nNew York, NY 10009\\n(40.72...  \n",
      "3  145 Stanton Street\\nNew York, NY 10002\\n(40.72...  \n",
      "4  111 Columbia Street\\nNew York, NY 10002\\n(40.7...  \n",
      "\n",
      "[5 rows x 157 columns]\n",
      "(363, 157)\n"
     ]
    }
   ],
   "source": [
    "to_merge = [\"class_size\", \"demographics\", \"survey\", \"hs_directory\"]\n",
    "\n",
    "for m in to_merge:\n",
    "    combined = combined.merge(data[m], on=\"DBN\", how=\"inner\")\n",
    "\n",
    "print(combined.head(5))\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing values\n",
    "\n",
    "- Calculate the means of all of the columns in combined using the pandas.DataFrame.mean() method.\n",
    "- Fill in any missing values in combined with the means of the respective columns using the pandas.DataFrame.fillna() method.\n",
    "- Fill in any remaining missing values in combined with 0 using the df.fillna() method.\n",
    "- Display the first few rows of combined to verify that the correct operations occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=combined.mean()\n",
    "combined=combined.fillna(mean)\n",
    "combined=combined.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a School District Column for Mapping\n",
    "\n",
    "- Write a function that extracts the first two characters of a string and returns them.\n",
    "- Apply the function to the DBN column of combined, and assign the result to the school_dist column of combined.\n",
    "- Display the first few items in the school_dist column of combined to verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    01\n",
       "1    01\n",
       "2    01\n",
       "3    01\n",
       "4    01\n",
       "Name: school_dist, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def character(val):\n",
    "    ext=val[0:2]\n",
    "    return ext\n",
    "combined[\"school_dist\"]=combined[\"DBN\"].apply(character)\n",
    "combined[\"school_dist\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Analyzing and Visualizing the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Correlations With the r Value\n",
    "\n",
    "- Use the pandas.DataFrame.corr() method on the combined dataframe to find all possible correlations. Assign the result to correlations.\n",
    "- Filter correlations so that it only shows correlations for the column sat_score.\n",
    "- Display all of the rows in correlations and look them over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = combined.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sat_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2525\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sat_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-62bb4125ccdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sat_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3843\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3844\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2525\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2527\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sat_score'"
     ]
    }
   ],
   "source": [
    "combined[\"sat_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Mapping the Schools With Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "m = Basemap(\n",
    "    projection='merc', \n",
    "    llcrnrlat=40.496044, \n",
    "    urcrnrlat=40.915256, \n",
    "    llcrnrlon=-74.255735, \n",
    "    urcrnrlon=-73.700272,\n",
    "    resolution='i'\n",
    ")\n",
    "\n",
    "m.drawmapboundary(fill_color='#85A6D9')\n",
    "m.drawcoastlines(color='#6D5F47', linewidth=.4)\n",
    "m.drawrivers(color='#6D5F47', linewidth=.4)\n",
    "\n",
    "longitudes=combined[\"lon\"].tolist()\n",
    "latitudes = combined[\"lat\"].tolist()\n",
    "m.scatter(longitudes, latitudes, s=20, zorder=2, latlon=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting our statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "m = Basemap(\n",
    "    projection='merc', \n",
    "    llcrnrlat=40.496044, \n",
    "    urcrnrlat=40.915256, \n",
    "    llcrnrlon=-74.255735, \n",
    "    urcrnrlon=-73.700272,\n",
    "    resolution='i'\n",
    ")\n",
    "\n",
    "m.drawmapboundary(fill_color='#85A6D9')\n",
    "m.drawcoastlines(color='#6D5F47', linewidth=.4)\n",
    "m.drawrivers(color='#6D5F47', linewidth=.4)\n",
    "\n",
    "longitudes = combined[\"lon\"].tolist()\n",
    "latitudes = combined[\"lat\"].tolist()\n",
    "m.scatter(longitudes, latitudes, s=20, zorder=2, latlon=True, c=combined[\"ell_percent\"], cmap=\"summer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting percentage by districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "m = Basemap(\n",
    "    projection='merc', \n",
    "    llcrnrlat=40.496044, \n",
    "    urcrnrlat=40.915256, \n",
    "    llcrnrlon=-74.255735, \n",
    "    urcrnrlon=-73.700272,\n",
    "    resolution='i'\n",
    ")\n",
    "\n",
    "m.drawmapboundary(fill_color='#85A6D9')\n",
    "m.drawcoastlines(color='#6D5F47', linewidth=.4)\n",
    "m.drawrivers(color='#6D5F47', linewidth=.4)\n",
    "\n",
    "longitudes = districts[\"lon\"].tolist()\n",
    "latitudes = districts[\"lat\"].tolist()\n",
    "m.scatter(longitudes, latitudes, s=50, zorder=2, latlon=True, c=districts[\"ell_percent\"], cmap=\"summer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
